{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a14ca0d",
   "metadata": {},
   "source": [
    "# Deep Learning ISD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4247dd90",
   "metadata": {},
   "source": [
    "## 1. Auteurs et liens\n",
    "\n",
    "| Nom  | Prénom | Courriel | Groupe | Github |\n",
    "| :-------------: | :-------------: | :-------------: | :-------------: | :-------------: |\n",
    "| AIT BELKACEM  | Moncef Karim  | moncef.ait-belkacem@universite-paris-saclay.fr  | LDDIM2  |<a href=\"https://github.com/MK8BK\">MK8BK</a>|\n",
    "| Tran--Guery | Thimoté | thimote.tran--guery@universite-paris-saclay.fr  | LDDIM2  |<a href=\"https://github.com/Thimote91\">Thimote91</a>|\n",
    "\n",
    "[Repositoire GitHub du projet](https://github.com/MK8BK/Deep_Learning_ISD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a29cb8",
   "metadata": {},
   "source": [
    "## 2. Introduction\n",
    "Ceci est le projet final de l'UE <a href=\"https://nicolas.thiery.name/Enseignement/IntroScienceDonnees/\">Initiation à la Science des Données</a> offert en L1-S2 à l'Université Paris-Saclay.\n",
    "\n",
    "Il s'agit d'un classificateur de caractères hexadécimaux manuscrits en python.\n",
    "\n",
    "Plus précisément, c’est une implémentation d’un réseau neuronal, visant la prédiction de caractères manuscrits de `0-9/A-F` (16 classes),\n",
    "\n",
    "dans le data set `EMNIST`.\n",
    "\n",
    "On utilise pour cela le module de calcul numérique `numpy`, le module de visualisation `matplotlib` et le module de traitement d'image `PIL`.\n",
    "\n",
    "(En outre des modules suivants de la librairie standard python : `os`, `random`, `pickle`, `typing`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dc2d92",
   "metadata": {},
   "source": [
    "## 3. Aspects Théoriques "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fc45ae",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8451ac",
   "metadata": {},
   "source": [
    "A completer ...\n",
    "\n",
    "...\n",
    "\n",
    "...\n",
    "\n",
    "...\n",
    "\n",
    "...\n",
    "\n",
    "partie math latex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc0baa9",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0866da",
   "metadata": {},
   "source": [
    "## 4. Détails de l'implémentation \n",
    "\n",
    "L'outil principal à notre disposition est l'objet np.array du module `numpy` .\n",
    "\n",
    "Toute référence au mot matrice est en fait un 2d np.array (np.matrix ne se prête pas à la tâche) .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16e36e2",
   "metadata": {},
   "source": [
    "### 4.1 Set de données\n",
    "\n",
    "On dispose de `38400` images, reparties en `16` classes, soit `2400` images par classe.\n",
    "\n",
    "Chaque image est au format `jpeg`.\n",
    "\n",
    "Ces fichiers sont dans le dossier `./EMNIST_DATA_SET/{classe de l'image}/{nom de l'image}.jpeg`.\n",
    "\n",
    "De plus chaque image contient sa classe en premier caractère.\n",
    "\n",
    "\n",
    "<img src=\"./EMNIST_DATA_SET/0/0_char_102479.jpeg\"  width=56 style=\"float: left\"/>\n",
    "<img src=\"./EMNIST_DATA_SET/1/1_char_16442.jpeg\"  width=56 style=\"float: left\"/>\n",
    "<img src=\"./EMNIST_DATA_SET/2/2_char_7136.jpeg\"  width=56 style=\"float: left\"/>\n",
    "<img src=\"./EMNIST_DATA_SET/3/3_char_55992.jpeg\"  width=56 style=\"float: left\"/>\n",
    "<img src=\"./EMNIST_DATA_SET/4/4_char_80661.jpeg\"  width=56 style=\"float: left\"/>\n",
    "<img src=\"./EMNIST_DATA_SET/5/5_char_73026.jpeg\"  width=56 style=\"float: left\"/>\n",
    "<img src=\"./EMNIST_DATA_SET/6/6_char_19045.jpeg\"  width=56 style=\"float: left\"/>\n",
    "<img src=\"./EMNIST_DATA_SET/7/7_char_107973.jpeg\"  width=56 style=\"float: left\"/>\n",
    "<img src=\"./EMNIST_DATA_SET/8/8_char_22810.jpeg\"  width=56 style=\"float: left\"/>\n",
    "<img src=\"./EMNIST_DATA_SET/9/9_char_110343.jpeg\"  width=56 style=\"float: left\"/>\n",
    "<img src=\"./EMNIST_DATA_SET/A/A_char_4502.jpeg\"  width=56 style=\"float: left\"/>\n",
    "<img src=\"./EMNIST_DATA_SET/B/B_char_9251.jpeg\"  width=56 style=\"float: left\"/>\n",
    "<img src=\"./EMNIST_DATA_SET/C/C_char_15156.jpeg\"  width=56 style=\"float: left\"/>\n",
    "<img src=\"./EMNIST_DATA_SET/D/D_char_35808.jpeg\"  width=56 style=\"float: left\"/>\n",
    "<img src=\"./EMNIST_DATA_SET/E/E_char_712.jpeg\"  width=56 style=\"float: left\"/>\n",
    "<img src=\"./EMNIST_DATA_SET/F/F_char_99118.jpeg\" width=56 style=\"float: left\"/>\n",
    "<div style=\"clear: both\"></div>\n",
    "\n",
    "Par exemple : `./EMNIST_DATA_SET/0/0_char_102479.jpeg` est le path vers la première image (celle du 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0222f5",
   "metadata": {},
   "source": [
    "### 4.2 Modularité\n",
    "\n",
    "Notre implémentation de Deep Learning se décompose en 6 fichiers situes dans le dossier `./src/` :\n",
    " - `LoadData.py`\n",
    " - `Functions.py`\n",
    " - `Layers.py`\n",
    " - `NeuralNetwork.py`\n",
    " - `Utilities.py`\n",
    "\n",
    "Importons ces six fichiers :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b9b497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.LoadData import *\n",
    "from src.Functions import *\n",
    "from src.Layers import *\n",
    "from src.NeuralNetwork import *\n",
    "from src.Trainer import *\n",
    "from src.Utilities import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a0951d",
   "metadata": {},
   "source": [
    "Utilisons la fonction `show_source()` définie dans `./src/Utilities.py` afin d'observer en détails les objets qui seront manipulés par la suite."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc922478",
   "metadata": {},
   "source": [
    "### 4.3 `LoadData`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22a01946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F']\n"
     ]
    }
   ],
   "source": [
    "#Global list[str] of classes(single characters)\n",
    "print(CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb53f449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function char_to_label in module src.LoadData:\n",
      "\n",
      "char_to_label(character: str) -> int\n",
      "    Convert the character representation of the class into its integer representation\n",
      "    @param: character: str , has to be in the global defined classes\n",
      "    @return: the integer representation of said character\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(char_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2c359ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function label_to_char in module src.LoadData:\n",
      "\n",
      "label_to_char(label: int) -> str\n",
      "    Convert the integer representation of the class into its character representation\n",
      "    @param: label: int , has to be a valid index of the global defined classes\n",
      "    @return: the character representation of said integer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(label_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0439a3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function load_pil_image in module src.LoadData:\n",
      "\n",
      "load_pil_image(str_path: str) -> <module 'PIL.Image' from 'C:\\\\Users\\\\User\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\site-packages\\\\PIL\\\\Image.py'>\n",
      "    Returns a grayscale PIL image given the full relative str_path\n",
      "    @param: str_path: the full relative str_path to the image file\n",
      "    @return: im: a PIL Image object (single channel: grayscale)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(load_pil_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c304b845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function load_numpy_image in module src.LoadData:\n",
      "\n",
      "load_numpy_image(str_path: str) -> <built-in function array>\n",
      "    Returns the flattened numpy representation of an image \n",
      "                        given the full relative str_path\n",
      "    @param: str_path: the full relative str_path to the image file\n",
      "    @return: im: a normalized np.array of dimensions (h*w,1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(load_numpy_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c66ca56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function make_input_matrix in module src.LoadData:\n",
      "\n",
      "make_input_matrix(samples: list) -> <built-in function array>\n",
      "    Returns the matrix representation of s samples\n",
      "    @param: samples: a list of flattened np.array 's, \n",
      "                    each representing a sample image\n",
      "    @return: input_matrix: a matrix (2d np.array) containing one sample per column,\n",
      "                                     1 feature(pixel value) per row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(make_input_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b4afc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function make_labels in module src.LoadData:\n",
      "\n",
      "make_labels(filenames: list) -> <built-in function array>\n",
      "    Returns the class label for each image filename in filenames\n",
      "    @param: filenames: a list of strings, relative str_paths to files\n",
      "    @return: labels: a list of int labels : the class of each file\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(make_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad1d502e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function make_labels_matrix in module src.LoadData:\n",
      "\n",
      "make_labels_matrix(labels: list, classes: list = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F']) -> <built-in function array>\n",
      "    Returns the one hot encoded matrix representation of the labels, \n",
      "                        given a list of char labels\n",
      "    @param: labels: a list of strings, filepaths\n",
      "    @return: labels_matrix: a 2 np.array of 16 rows, each column is an image\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(make_labels_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7039ada4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function make_random_batch in module src.LoadData:\n",
      "\n",
      "make_random_batch(path: str, batch_size: int, classes: list, equilibrium: bool = True) -> list\n",
      "    Returns a list of filenames randomly, equal per class or not\n",
      "    @param: path: the path to the data_set folder\n",
      "    @param: batch_size: the number of images in the batch\n",
      "    @param: classes: a list of str representations of the classes\n",
      "    @param: equilibrium: a bool, wether or not to equalize images per class\n",
      "    @return: batch: a list of strings, \n",
      "            the paths to the randomly selected images\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(make_random_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "647691c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function load_training_set in module src.LoadData:\n",
      "\n",
      "load_training_set(path_str: str, batch_size: int, classes: list = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F'], equilibrium: bool = True) -> tuple\n",
      "    Returns a training input and labels matrices randomly, \n",
      "                                    equal per class or not\n",
      "    @param: path: the path to the data_set folder\n",
      "    @param: batch_size: the number of images in the batch\n",
      "    @param: classes: a list of str representations of the classes\n",
      "    @param: equilibrium: a bool, wether or not to equalize images per class\n",
      "    @return: batch: X: an input matrix of shape (784,batch_size) \n",
      "                    Y: a corresponding labels matrix of shape (16, batch_size)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(load_training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc91a9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function load_prediction_image in module src.LoadData:\n",
      "\n",
      "load_prediction_image(path_str)\n",
      "    Loads a single image located at path_str\n",
      "    @param: path_str: relative path to the image\n",
      "    @return: x: a 784x1 input matrix\n",
      "             im: PIL representation of the image\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(load_prediction_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ec77f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function load_data_set in module src.LoadData:\n",
      "\n",
      "load_data_set(path_str)\n",
      "    Loads entire data set at path_str\n",
      "    @param: path_str: root path of data_set\n",
      "    @return: X: an imput matrix of shape (784, 38400)\n",
      "             Y: a labels matrix of shape (16, 38400)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(load_data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20534d4",
   "metadata": {},
   "source": [
    "### 4.4 `Functions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc1e2356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Activation in module src.Functions:\n",
      "\n",
      "class Activation(builtins.object)\n",
      " |  Activation(fn, dfn)\n",
      " |  \n",
      " |  Abstract Activation function class\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, fn, dfn)\n",
      " |      @param: Callable self.fn: forward pass function\n",
      " |      @param: Callable self.dfn: backward pass function\n",
      " |              (derivative of forward pass function)\n",
      " |  \n",
      " |  backward(self, x)\n",
      " |      apply backward pass function to input gradient matrix(2d np.array)\n",
      " |      @param: x : 2d np.array , gradient of loss wrt layer output\n",
      " |      @return: a 2d np.array (same shape as x), elementwise evaluation using dfn\n",
      " |              ie: gradient of error wrt linear part of layer\n",
      " |  \n",
      " |  forward(self, x)\n",
      " |      apply forward pass function to input matrix (2d np.array)\n",
      " |      @param: x : a 2d np.array, the results of the linear part of the layer\n",
      " |      @return: a 2d np.array (same shape as x), elementwise evaluation using fn\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe1baaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Activation in module src.Functions object:\n",
      "\n",
      "class Activation(builtins.object)\n",
      " |  Activation(fn, dfn)\n",
      " |  \n",
      " |  Abstract Activation function class\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, fn, dfn)\n",
      " |      @param: Callable self.fn: forward pass function\n",
      " |      @param: Callable self.dfn: backward pass function\n",
      " |              (derivative of forward pass function)\n",
      " |  \n",
      " |  backward(self, x)\n",
      " |      apply backward pass function to input gradient matrix(2d np.array)\n",
      " |      @param: x : 2d np.array , gradient of loss wrt layer output\n",
      " |      @return: a 2d np.array (same shape as x), elementwise evaluation using dfn\n",
      " |              ie: gradient of error wrt linear part of layer\n",
      " |  \n",
      " |  forward(self, x)\n",
      " |      apply forward pass function to input matrix (2d np.array)\n",
      " |      @param: x : a 2d np.array, the results of the linear part of the layer\n",
      " |      @return: a 2d np.array (same shape as x), elementwise evaluation using fn\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ReLu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6741ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Activation in module src.Functions object:\n",
      "\n",
      "class Activation(builtins.object)\n",
      " |  Activation(fn, dfn)\n",
      " |  \n",
      " |  Abstract Activation function class\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, fn, dfn)\n",
      " |      @param: Callable self.fn: forward pass function\n",
      " |      @param: Callable self.dfn: backward pass function\n",
      " |              (derivative of forward pass function)\n",
      " |  \n",
      " |  backward(self, x)\n",
      " |      apply backward pass function to input gradient matrix(2d np.array)\n",
      " |      @param: x : 2d np.array , gradient of loss wrt layer output\n",
      " |      @return: a 2d np.array (same shape as x), elementwise evaluation using dfn\n",
      " |              ie: gradient of error wrt linear part of layer\n",
      " |  \n",
      " |  forward(self, x)\n",
      " |      apply forward pass function to input matrix (2d np.array)\n",
      " |      @param: x : a 2d np.array, the results of the linear part of the layer\n",
      " |      @return: a 2d np.array (same shape as x), elementwise evaluation using fn\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "227fb013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Activation in module src.Functions object:\n",
      "\n",
      "class Activation(builtins.object)\n",
      " |  Activation(fn, dfn)\n",
      " |  \n",
      " |  Abstract Activation function class\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, fn, dfn)\n",
      " |      @param: Callable self.fn: forward pass function\n",
      " |      @param: Callable self.dfn: backward pass function\n",
      " |              (derivative of forward pass function)\n",
      " |  \n",
      " |  backward(self, x)\n",
      " |      apply backward pass function to input gradient matrix(2d np.array)\n",
      " |      @param: x : 2d np.array , gradient of loss wrt layer output\n",
      " |      @return: a 2d np.array (same shape as x), elementwise evaluation using dfn\n",
      " |              ie: gradient of error wrt linear part of layer\n",
      " |  \n",
      " |  forward(self, x)\n",
      " |      apply forward pass function to input matrix (2d np.array)\n",
      " |      @param: x : a 2d np.array, the results of the linear part of the layer\n",
      " |      @return: a 2d np.array (same shape as x), elementwise evaluation using fn\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Tanh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c074f7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SoftmaxCrossEntropyLoss in module src.Functions:\n",
      "\n",
      "class SoftmaxCrossEntropyLoss(builtins.object)\n",
      " |  SoftmaxCrossEntropyLoss(eps: float = 1e-09, axis=0)\n",
      " |  \n",
      " |  Softmax Cross Entropy loss function wrapper class\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, eps: float = 1e-09, axis=0)\n",
      " |      @param: optional eps = 1e-9: safety pre-log clipping precision\n",
      " |      @param: optional axis = 0 (columns) \n",
      " |                          apply softmax by columns or rows of matrix\n",
      " |  \n",
      " |  backward(self, y)\n",
      " |      return gradient of loss with respect to prediction \n",
      " |          for Softmax Cross Entropy Loss function\n",
      " |      @param: y : 2d np.array of labels\n",
      " |      @return: softmax_preds - labels \n",
      " |              (gradient of loss wrt linear output layer)\n",
      " |  \n",
      " |  forward(self, x)\n",
      " |      apply softmax to matrix by axis (0 columns; 1 rows)\n",
      " |      @param: x : a 2d np.array, the results of the linear part of the layer\n",
      " |      @return: self.p (cached for backward use), axis-wise softmax\n",
      " |                  probability distribution per axis\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(SoftmaxCrossEntropyLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89d9a40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function compute_cost in module src.Functions:\n",
      "\n",
      "compute_cost(p, y, eps=1e-09)\n",
      "    Compute cost using Cross Entropy loss function\n",
      "    @param: p : np.array of shape (16, batch_size),\n",
      "             column wise probabilities per sample\n",
      "    @param: y : one hot encoded np.array of labels\n",
      "    @return: loss (float)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(compute_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f265ed13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function predicted_labels in module src.Functions:\n",
      "\n",
      "predicted_labels(p)\n",
      "    Converts a columnwise matrix of probabilities into prediction labels\n",
      "    @param: p : np.array of shape (16, batch_size), sum(column)=1\n",
      "    @return: a list characters, predictions based on max probability per image\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01a7ba8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function percent_good in module src.Functions:\n",
      "\n",
      "percent_good(p, y)\n",
      "    Returns a percentage (range 0 to 100 float) of good predictions\n",
      "    @param: p : np.array of shape (16, batch_size), sum(column)=1\n",
      "    @param: y : np.array of shape (16, batch_size), one-hot-encoded\n",
      "    @return: accuracy : a float between 0 and 100,\n",
      "            the percentage of good predictions\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(percent_good)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4514b31b",
   "metadata": {},
   "source": [
    "### 4.5 `Layers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5891fa14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class DenseLinearLayer in module src.Layers:\n",
      "\n",
      "class DenseLinearLayer(builtins.object)\n",
      " |  DenseLinearLayer(N, F)\n",
      " |  \n",
      " |  DenseLinearLayer wrapper class\n",
      " |      Fully connected, unactivated layer\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, N, F)\n",
      " |      Constructor uses glorot initialisation\n",
      " |      @param: N : int, number of neurons\n",
      " |      @param: F : int, number of input features \n",
      " |                  (neurons in previous layer)\n",
      " |  \n",
      " |  backward(self, dZ, lr)\n",
      " |      Performs the backward pass given gradient matrix\n",
      " |      @param: dZ : an np.array of shape (N, batch_size)\n",
      " |      @action: updates self.W and self.B using SGD\n",
      " |      @return: dX : gradient of error wrt previous layer\n",
      " |              shape (F, batch_size)\n",
      " |  \n",
      " |  forward(self, X)\n",
      " |      Performs WX+B given input matrix\n",
      " |      @param: X : an np.array of shape (F, batch_size)\n",
      " |      @return: Z (cached for backward pass), weights*inputs + biases\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(DenseLinearLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a22e53f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class DenseActivatedLayer in module src.Layers:\n",
      "\n",
      "class DenseActivatedLayer(DenseLinearLayer)\n",
      " |  DenseActivatedLayer(N, F, A)\n",
      " |  \n",
      " |  Child of DenseLinearLayer, uses an activation function (R->R)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DenseActivatedLayer\n",
      " |      DenseLinearLayer\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, N, F, A)\n",
      " |      Constructor, uses DenseLinearLayer constructor\n",
      " |          declares A, activation function for layer instance\n",
      " |      @param: N : int, number of neurons\n",
      " |      @param: F : int, number of input features \n",
      " |                  (neurons in previous layer)\n",
      " |      @param: A : activation function, \n",
      " |                  instance of src.Functions.Activation\n",
      " |  \n",
      " |  backward(self, dA_of_Z: <built-in function array>, lr) -> <built-in function array>\n",
      " |      Performs the backward pass given gradient matrix\n",
      " |      @param: dA_of_Z : an np.array of shape (N, batch_size)\n",
      " |      @action: elementwise activation.backward(Z)*dA_of_Z (Hadamrd Product)\n",
      " |      @action: updates self.W and self.B using super().backward(dZ)\n",
      " |      @return: dX : gradient of error wrt previous layer\n",
      " |              shape (F, batch_size)\n",
      " |  \n",
      " |  forward(self, X: <built-in function array>) -> <built-in function array>\n",
      " |      Performs A(WX+B) given input matrix\n",
      " |      @param: X : an np.array of shape (F, batch_size)\n",
      " |      @return: A_of_z (cached for backward pass),\n",
      " |           forward_activation(weights*inputs + biases)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from DenseLinearLayer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(DenseActivatedLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f13a1b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class OutputLayer in module src.Layers:\n",
      "\n",
      "class OutputLayer(DenseLinearLayer)\n",
      " |  OutputLayer(N, F, C)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      OutputLayer\n",
      " |      DenseLinearLayer\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, N, F, C)\n",
      " |      Constructor, uses DenseLinearLayer constructor\n",
      " |          declares C, combined cost and activation function for layer\n",
      " |      @param: N : int, number of neurons (same as number of classes)\n",
      " |      @param: F : int, number of input features\n",
      " |                  (neurons in previous layer)\n",
      " |      @param: C : cost and activation function, \n",
      " |                  Only implemented SoftmaxCrossEntropy for now (works best)\n",
      " |  \n",
      " |  backward(self, Y, lr)\n",
      " |      Performs the backward pass given labels matrix\n",
      " |      @param: Y : an np.array of shape (N, batch_size)\n",
      " |      @action: loss/cost function.backward(Y)\n",
      " |      @action: updates self.W and self.B using super().backward(dZ)\n",
      " |      @return: dX : gradient of error wrt previous layer\n",
      " |              shape (F, batch_size)\n",
      " |  \n",
      " |  forward(self, X)\n",
      " |      Performs C(WX+B) given input matrix\n",
      " |      @param: X : an np.array of shape (F, batch_size)\n",
      " |      @return: A_of_z (cached for backward pass),\n",
      " |           forward_activation(weights*inputs + biases)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from DenseLinearLayer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(OutputLayer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e5d4a1",
   "metadata": {},
   "source": [
    "### 4.6 `NeuralNetwork`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "daae2133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class NeuralNetwork in module src.NeuralNetwork:\n",
      "\n",
      "class NeuralNetwork(builtins.object)\n",
      " |  NeuralNetwork(layers)\n",
      " |  \n",
      " |  The NeuralNetwork wrapper class\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, layers)\n",
      " |      @param: layers : list[DenseLinearLayer]\n",
      " |          ordered, last must be OutputLayer\n",
      " |  \n",
      " |  backward(self, Y, lr=0.01)\n",
      " |      Backward pass of neural network\n",
      " |      @param: Y : a 2d np.array of shape (16, batch_size)\n",
      " |      @param: Optional lr=0.01 : Learning rate\n",
      " |      @action: perform backpropagation, use ____Layer.backward\n",
      " |              successively\n",
      " |      @return: None\n",
      " |  \n",
      " |  forward(self, X)\n",
      " |      Forward pass of neural network\n",
      " |      @param: X : a 2d np.array of shape (784, batch_size)\n",
      " |      @return: res : model prediction: of shape (16, batch_size)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(NeuralNetwork)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76199b21",
   "metadata": {},
   "source": [
    "### 4.7 `Trainer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b085f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddb21f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c02ad317",
   "metadata": {},
   "source": [
    "### 4.8 `Utilities`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8cd515f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function image_grid in module src.Utilities:\n",
      "\n",
      "image_grid(images: Iterable[PIL.Image.Image], columns: int = 5, titles: Optional[Iterable] = None) -> matplotlib.figure.Figure\n",
      "    Return a figure holding the images arranged in a grid\n",
      "    \n",
      "    Optionally the number of columns and/or image titles can be provided.\n",
      "    \n",
      "    Example:\n",
      "    \n",
      "         >>> image_grid(images)\n",
      "         >>> image_grid(images, titles=[....])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(image_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5b93ca",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc7af6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fda33452",
   "metadata": {},
   "source": [
    "## 5. Démonstration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27205161",
   "metadata": {},
   "source": [
    "### 5.1 Entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5578932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.axes as axes\n",
    "epochs = 1201"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b6ec51",
   "metadata": {},
   "source": [
    "#### 5.1.1 Entrainement et test sur les memes mini_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f18edc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCE = SoftmaxCrossEntropyLoss()\n",
    "layers = [DenseActivatedLayer(112, 784, ReLu), OutputLayer(16, 112, SCE)]\n",
    "nn = NeuralNetwork(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8fe16e06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:    0 | Accuracy: 7.8125 %\n",
      "Iteration:   20 | Accuracy: 48.4375 %\n",
      "Iteration:   40 | Accuracy: 64.0625 %\n",
      "Iteration:   60 | Accuracy: 67.1875 %\n",
      "Iteration:   80 | Accuracy: 76.5625 %\n",
      "Iteration:  100 | Accuracy: 76.5625 %\n",
      "Iteration:  120 | Accuracy: 79.6875 %\n",
      "Iteration:  140 | Accuracy: 89.0625 %\n",
      "Iteration:  160 | Accuracy: 75.0 %\n",
      "Iteration:  180 | Accuracy: 78.125 %\n",
      "Iteration:  200 | Accuracy: 79.6875 %\n",
      "Iteration:  220 | Accuracy: 89.0625 %\n",
      "Iteration:  240 | Accuracy: 87.5 %\n",
      "Iteration:  260 | Accuracy: 84.375 %\n",
      "Iteration:  280 | Accuracy: 89.0625 %\n",
      "Iteration:  300 | Accuracy: 89.0625 %\n",
      "Iteration:  320 | Accuracy: 85.9375 %\n",
      "Iteration:  340 | Accuracy: 90.625 %\n",
      "Iteration:  360 | Accuracy: 85.9375 %\n",
      "Iteration:  380 | Accuracy: 92.1875 %\n",
      "Iteration:  400 | Accuracy: 92.1875 %\n",
      "Iteration:  420 | Accuracy: 84.375 %\n",
      "Iteration:  440 | Accuracy: 87.5 %\n",
      "Iteration:  460 | Accuracy: 81.25 %\n",
      "Iteration:  480 | Accuracy: 89.0625 %\n",
      "Iteration:  500 | Accuracy: 90.625 %\n",
      "Iteration:  520 | Accuracy: 92.1875 %\n",
      "Iteration:  540 | Accuracy: 82.8125 %\n",
      "Iteration:  560 | Accuracy: 93.75 %\n",
      "Iteration:  580 | Accuracy: 95.3125 %\n",
      "Iteration:  600 | Accuracy: 89.0625 %\n",
      "Iteration:  620 | Accuracy: 92.1875 %\n",
      "Iteration:  640 | Accuracy: 92.1875 %\n",
      "Iteration:  660 | Accuracy: 87.5 %\n",
      "Iteration:  680 | Accuracy: 98.4375 %\n",
      "Iteration:  700 | Accuracy: 95.3125 %\n",
      "Iteration:  720 | Accuracy: 92.1875 %\n",
      "Iteration:  740 | Accuracy: 90.625 %\n",
      "Iteration:  760 | Accuracy: 92.1875 %\n",
      "Iteration:  780 | Accuracy: 92.1875 %\n",
      "Iteration:  800 | Accuracy: 95.3125 %\n",
      "Iteration:  820 | Accuracy: 95.3125 %\n",
      "Iteration:  840 | Accuracy: 95.3125 %\n",
      "Iteration:  860 | Accuracy: 87.5 %\n",
      "Iteration:  880 | Accuracy: 92.1875 %\n",
      "Iteration:  900 | Accuracy: 96.875 %\n",
      "Iteration:  920 | Accuracy: 92.1875 %\n",
      "Iteration:  940 | Accuracy: 93.75 %\n",
      "Iteration:  960 | Accuracy: 96.875 %\n",
      "Iteration:  980 | Accuracy: 93.75 %\n",
      "Iteration: 1000 | Accuracy: 92.1875 %\n",
      "Iteration: 1020 | Accuracy: 96.875 %\n",
      "Iteration: 1040 | Accuracy: 98.4375 %\n",
      "Iteration: 1060 | Accuracy: 95.3125 %\n",
      "Iteration: 1080 | Accuracy: 92.1875 %\n",
      "Iteration: 1100 | Accuracy: 96.875 %\n",
      "Iteration: 1120 | Accuracy: 98.4375 %\n",
      "Iteration: 1140 | Accuracy: 95.3125 %\n",
      "Iteration: 1160 | Accuracy: 95.3125 %\n",
      "Iteration: 1180 | Accuracy: 92.1875 %\n",
      "Iteration: 1200 | Accuracy: 95.3125 %\n",
      "CPU times: total: 2min 7s\n",
      "Wall time: 1min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "accuracies1, costs1 = train_on_subset(nn, \"./EMNIST_DATA_SET/\",\n",
    "                                      epochs=epochs, batch_size=64, equilibrium=True,\n",
    "                                      lr=1, test_on_all=False, iter_test=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0e729ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAq7ElEQVR4nO2de7hfVXnnP28SjhJwSAIpg0IIYNQinQaMKTRoiZcEKVQuGoHipUNLvYwFpBCoZIoPFA0ygnaoCK0jliiJBDBE20ApPF5mBkwkYBAZsBouBokBlAgPJyTv/LH25rd+K3vv3/38zjm/7+d5fs/ee+11edda++z3rHevtV5zd4QQQgw2E/otgBBCiP4jZSCEEELKQAghhJSBEEIIpAyEEEIAk/otQLvstddePnPmzH6LIYQQY4Z169b9yt2nF90bs8pg5syZrF27tt9iCCHEmMHMNpbdk5lICCGElIEQQggpAyGEEEgZCCGEQMpACCEETSgDM/uymT1lZhuS8GlmdruZPZwdp2bhZmZfMLNHzOx+MzusIM/pZvY9M9tgZsdH4d80s1d3oV5CCCFaoJmRwVeAowvCzwfucPdZwB3ZNcC7gFnZ7wzgiwVpTwGuBuYCZwGY2XHAve7+i+bFF0II0Q0aKgN3/w7wdMGtdwPXZefXAcdH4V/1wP8FppjZPknabcBk4BXAdjObRFAKl7VaASEGkeFhuPXWcGwm7k03hd/Wrc2n66TMsrSdlD+SdFLXdsoZDe3SyTeDvd19U3b+JLB3dv4a4LEo3uNZWMzXCErjduBS4KPAP7v781UFmtkZZrbWzNZu3ry5A9GFGNusWQMnnRSOzcRdtCj8li5tPl0nZZal7aT8kaSTurZTzqhoF3dv+ANmAhuSsGeT62ey42rgyCj8DmBORd5TCUphd+Ba4EbgiEYyvelNb3IhBpUXX3RftSocm4m7cmX4Pfdc8+k6KbMsbSfljySd1LWdckaqXYC1XvJO7WRk8Mvc/JMdn8rCnwD2i+Ltm4WVsQT4O8J3hO8BHwQu6kAuMUK0aqpI43Z7KD5SQ/tW6FSmOH18PjQExx0XjkVpbroJli8PR4Bjj4VddilO146MrfZnXu7uuxeXn5uxWm2ntMwyGfIyli2D886DFSvq23Tr1tBeF1wQzoeGYOHC8J/600/DkiXhWJV3Kn/aD2kfDg+H/Bcu3Lld+vIsl2kJ94Yjg88C52fn5wOXZed/DPwLYMDhwD0V+c4CVmTnZwLvJ3xL+E4jmTQy6D+rVrnvsks4thO3lfTdlmek6FSmOH2zea1a5T5xovuECeHYKG0r+VbJ0m5dc3lzWVtNG5dZJkNehpk7hLaJ63HhhSEMwnmc16JFIXzRouq8U/kb9UM3+qRVqBgZNKMIvg5sInz0fRw4PQvfk2ACehj4N2BaFm7AVcBPgR9RbSJaAczKzn8H+N/AA8BJjeSSMug/rZoq0rjdHoqP1NC+FTqVKU7fbF65WeiGG8KxUdpW8q2Spd26xmasdtLGZZbJkJdx/fXu557rvnx5fT2eey601/nnh/M4ry1bgoLYsqU671T+Rv3QjT5plY6UwWj9SRn0jl6/VDu1Pcd/eOkfbP6H3I4MZWHpH3SVPEV5vfhi7UUTv1DK7MVF4c28iPOXXVpOznPP1V5qjerUitJZuTLkecEF7suWVSuh9DqX6bnnist97rmQb/7yjmmmPlVtn8q+fHnIs+r7Sto3uRI599xQ9zKFEOeXl3HDDTvLvGWL+wknuJ9zToiX13/Zsp0VWTtIGYiW6LW5pZP80yF5OpTPh/jtyFAWlg71q+QpymvVqpoJIjY1xCaKIlNHHN6MiSY2gxSZNC68sHavUZ1aMUdNnFhrf7Nq81R6nct04YXF5eb3c7NOTDP1qWr7VPYJE0KeeXjaL0V9E5uXzMpNRXF+eRkTJuwscy5L3iZ5Hc12NnG1g5SBaAmNDHYuTyOD4jbUyGD8jAws3B97zJkzx+XcRgghmsfM1rn7nKJ7Y9bTmeiceGpb0RTFRvGaTd9M3Pg+7By3lfTp/fTe1q1hkc/ixWFK3/Aw3HwzrF8P554Ld90V0h17bDiuXh2ORx0Fl18OhxwCr3wlLFgAt90G27aFaZvHHlsvb54uDy8qd80amD8/5BPHLavT1q1w8cXh3vbtsHEjzJoFF11UnGcu24IFcOed1e23enWID/DSS/DDH4IZHHZYqO+xx4Z4l14Ks2fDMcfsXP+87978ZjjzTPjsZ+Hqq+ENb4D77oNJk8I0zd13r5Yhbs+8Tm9+M3z4w+H+pElhkdbuu9fHW70aXnghlDV7NkycGPI66ii44opa22/dWl+PO++sbzOob7e4j/J+z8uZMwfe8Y5a/kND4Xm65576+hbVL2+vtL/yZ232bDj++Pp4Vf3YEWVDhtH+k5moc1qxDZdNqetkamnZ/Wbt+c3mX2Wnzu/HduX0m0SRXTy3AVfZqtNvCUXlxjbkqu8OOXke6a8sz1y2Ivt32kaxHTu3T6e28NiGX1T/vPwjjwzxfvd3y2WtkiFuizTP+JfGi7+bxN8v0m9KaT3KbPnpvbjfYxt+nH/8PKV9U9ZeaVvG3zGqvi+1CjITiSI0MtDIIG4jjQzG/8igykwkZdBlWnlBjkSaVuO1+rCl+RflAzu/GNO0UJxPo3uNlFP+or/nHtixI4QvWVL7g12/Hj75ydrLqdX6FL1ki17y+QukrA3mzQsvk7PPDsoofol/61s1OYeG6tsyl6XsBRq337x5NWU2cWJ44ecvTXfYsKFYGRa9rIrqUKbU8hdvkRKFIMeGDaF+w8PwkY/A5z8PP/hBrV2ffjqEf/GLMG1afZ/H/TtxYlBecX2+//3yfkv7tageEMpYt66mYHJi2SEoaqg9Y/E/Enn/fv/7tf7OlUfZM5e3U95Xc+YE5dCuiahKGfTd3NPub7SaidqZNtnLNK3Ga3UYWjZ1MJ0W2cz0y7IpiI2mJ1bVNR2yFw3lY7NFq/VpNP0wNS2UtUG8yjU178Rypm3ZyLQSt186/TM2p8RTUoum7jYyiVWZu+Lpkal5LZbjwgtrMh55ZH27xu2T9nnav2l9qvqtaPpuWo+4jLztimSPTXhpX6WrmFOzUtkzl7dTN6aVustMNKJoZKCRgUYGGhmMxZGBlEGfqXpZxzbm/IFJX9bN2MqbeSnFZV56abDxPvhg7Y+pqtzh4SBn2YNeZnMvepmV2XbjNLF9uKgeRffSl3p8TP/w05fo/PnhhbxuXe2PMbad53+ceX/FL/Sc1P78zW/CN74BM2bArrvWXh5Fiqes3+MXW2rDTu3MeR2LXkpLl4bvD/FLNFc8sRKJvxOUlVUkc1mbx+2TttNtt8Ezz8C118JHPwonn1x7VuI6Fymn+FleuhQ+9jG46qpandPvGemzlT5H8TeE+LtJo3SN5Iyfl9tvr//HpKjsRt99mkFmolFMlRmnaHVm2WrVqlk0zZgr0jLzXz6srSo3XglaNAQum41TZOYom/WRru4sMz2V3Uvbr2iWSGqSitPkZoJ8mF60MrZoRWzZzJR4tk5VH1f1e9XsljKzR5m5IjWvxPIUrdAtK6tI5rI2j9snbaeJE+vlKjLzVK2ijvsjn4WU1zmd6VS0cjhu43SlcNkzWfT8VckZPy9Fm+SVzWzqlZmo7XUGZnYm8BeEjemudfcrs/BpwHLCTqc/Bxa5+zNJ2nkEd5jDwCnu/rCZTSFsXHe0u+9oV66xxsKFsHJl7T+qmMWLa8ehoRBv/nyYO7cWvyp9fm/+fDj00BC2YEHtvKzM7dvrRwannVZd7vz5Iezss0PcefPgda+ryb1iRbh/1FFw0EG1/6jyvFasqB8Z5GljedI0CxfW8k3rUXQvbou5c+uPaXvE7ZmnOeSQ2sggr/P27eG/5TxuLvPZZ8P73lc8MsjLfMMb6kcGVX1c1u95HfM+jf9bT9PmdczbN+6rmTN3HhnE8sybF/otHxlUlVUkc1mbV40MDj20fmQQPytxnfPnpurvJx4ZnHZa+cig7DmK/zuP+75RukZyxs/LiSeGkUEeVlR2/vwU1bUrlGmJqh9wCLCBsN30JMKupa/N7l1G/dbWSwvS30Twc3Ak8D+ysMuBo5qVYbyMDOLl7fES9aKl6ukS+nQnxaK88vTxsv+ysvMl80XbPaRbI8T5F+34WLWNQFx2uhVAWkYj+VeudP/KV9xPOsl948b6pfuxPLlMZW1QVK9mtoHI87j++rCNwLJl1btclm2nkW5VEMtftWVDvN1Cuttm2pdlz13Z81P27MVtFW9/UfVsltW/rG+qtrEokyWVt6yvmgkv2uakma1HqvKLt60o2wqkUd07hW5/QDaz9xL+gz89u14CvOjul5nZQ9lLfVPm9OYud399kn45wanNTOBtBA9nl7r7+5qVod1vBmf961msf3J9y+l6xZYt8MADsN8MeHRjcZxDDoE99wxxN2wIYdOnw+bN4firX8Eb3xjCi/I65BD4zXMhbMb+cMDM8rJn7F87P+SQ+jwfe7RWTi5HmibP/2c/r89nzz2L673XXqEeedqiMqrkj+WYPBmef76+nDh+LlNRGxTVK65/3L5vfGN9fVI5ivomjx/HLWrftO9m7B+Oudz/6VX1MsT55fUq6te0D+I4cZuXpSuSu6jOrdY/D0/7Ju6XvPyifkplieUt66tmwtPnM2/7ItmL8izKL26vnKq/jaK677knzP7Ps7ny6Ct3zqwJuv4B2cx+F/gmcATwAsGvwVp3/7iZPevuU7J4RnCHOSVJPxu4Okv7fsKoYIm7P9yg3DOAMwBmzJjxpo0bS96eFYw2ZeAeZkpMmRKGxTsSA9mECeEBMAtxt2wJ4VOmwGOPw377wq9/XZthkeaVp9+xAx59DGbsV5sNkZYNMHVq7Tx/SPM4zz5bK2fLllr+U6eG662/hf1nhPy3b4dHHw0fw/baK8hfVO899oDHHgvxpk3buYxcjjL5t2wJMy22bIHXvhZ+8QvYbbdw77fP1+SBTKaSNiiqV1z/uH2nTauvjzs89VR48U2fHu6nfZPHj/uwqH3zvti+vSY/1OSeMKFeBvfwsorbvqhf82cobf+0X8vSFcm9ZUtNzhn7hXyg+Nksq38envZN3C95+Wk/pbKk8pb1VTPhdc/n47W2L5K9KM+i/DZvDh+N85lr8d92TFXdzXqnDNr+gAucDqwDvkOw/1+ZhT+bxHumQT5vBa4AXkf41nA9sHej8kejmajV4Vyj+I12zMzjxGaCRsPtKorMEbHJqWjXxFjG1LwVm4Cqdn5sdrfOuLx0V8myeEXmorR9G+1QWWbmKDJxFdUpNw/Eu2KWmaLiPkhNbUVmrrQ+zZo2iurXrHmi6pmqMuekMqbPRpFJrsrUVSZzK/6eu2mSyfv6E59wP++8xv2UlrFlS/iYvGVL62U3C73ewhq4FPhodv4QsE92vg/wUEU6A24DpgHLgP2BPwL+rlGZo1EZVM3saSd+OtOmbMZQPBOhbP+bZmQqm71UtfAlnfUQz35I91dJ693qPv5xeensirJ48eyYsvZttHgsDSvbB7+sTvFMpKr9fOKZKnFfpjOYqvb2qZrNVTTrpWpmWtmzU/VMpbOKymZ1FT0bZTOSqma/Nft8lNFsnZsh7utm+ikto2xhXTfpiTIAfic7zgB+AkzJrgt9I5fk8UHgrOz8ZmA/4C3AFY3KH43KQCMDjQw0MtDIYKyODNpedGZm3yX4Qd4GfMLd78jC9yRMEZ0BbCRMLX26IP1k4FvAAnffZmZvAf6BMN30VHd/qKr8sbroLF2YBDsvBGq0mRjsvGArJ124FS/6+sM/DNP09t8/THd78MEwxe4LX6hNJU1X4+Ybf23YEOLmU/TiVarp5mzpIp1cziK5i1bNpqtx4/KvuKI2DbJowU9Ve8WLteKy80Vz+UI3gCefDBuh/eVfhgVPRXUs22wsbZdUprJN+OLFeulGblWL7MryrQpvhaLnrtGK8EbytiJbVZu1u1K+W3G7QS/7LkWLzkYR6cKkooVAjcxGRQu2iswzqZmgaAvgNCzdpyc2tcSLd8r22SlapFMld5UJIS8nLb9qwU9Ve6UypouI4rrnZeULnorqWLZ/T5VcZaan1LzTTF0a5VsV3gpF/dfItNJI3lZkq2qzZuvVSvxutFkr9LLvUtDeRKMHjQzq5dbIQCMDjQw0Mhj3I4Mqe2SV3bxoQU1si6+yhab5Fi3kKrOjpz5ly+y0sV/WMl+3RbK8+GLNLrppU+1evBgnXsRUtpgqtp+nC5tiO3u6kKvRd4Yym3wnduQimsmv22WOpvIb0Y+ym/le1WneVd8GR6q+9Ho2UT9+Y0EZVA2nY9NC2WyIIlNQo1kSab5FWy+XzbApMmEVlVG0N0vVUD6WId2iON73J916uGi/lrL9kPJy4xk4RfsPVc1AKput0+3hejP59dJU0e/yG9GPsoue1W7J0SifkayvlEGf0MhAI4Mi+v2feb/Lb4RGBr1DyqDHNDMFL36pV71A8xfSpk3VL6ZGCqHRlNT8pXndddVTL9My0ulvzU4lbPWPq9Mpfs3+8TWrxLpVdq/S9opeyDQa6zkoSBn0mGZmA8TmnirTSrrtbpnJopGpqNntfasWyBTJly6MKapjI49bzQyHOxk6tzIsb9a81a2ye5W2V/RCptFYz0FByqDHaGSgkcFIyN0PNDIYX1QpA00t7RK5+73UPWHsvrDRtMOyfFuZogetT8NrZgpbt6e/dWvaXDOe3rop20hPOxSim2hq6QiwalWx4/LUe1OjhVJF+bayeKfK7NHJbIZmTGGt0C1TQVU+vZBNJg4xlkEjg96jkYFGBkKMdjQy6AGxfbzKQ1eapsgW/eKL9ZuZNbKvV3n9asbbUyN50vud2Ha7aR9u9ttMP6fxyR4uRjP06gMycDbwAMEF5teBV2bhBwB3A48QfBQMFaQ9KUv7XWDPLOwgYHkzZfdbGcTmm6KFXVVbBjfa5rjRzJuixVGNZvKU1aFq1kw3TCLdNKs0O2urnwt8ZEYSo5meKAPgNcDPgF2z6xXAh6Lzk7Pzq4GPFKS/i+BD+TTg41nY14FZzZTfb2WgkUFzaGQgxOihl8rgMYJjmknAamABwWHNr4BJWbwjgDUF6f8dmEpwY/lhmvRjkP/6rQxyynwApC+n2El47Dy90RTMovOyvfNj2p3SKUSMnp3xRS/NRGcCW4HNwLIsbC/gkSjOfsCGgrTvJLjNvBXYg8zjWYPyzgDWAmtnzJjR42ZrjjLvYKnZIl6sle+/E2+PXGbqKDov86oV04rpRIgy9OyML3o1Mpia/Xc/HdgFuCUz+TSlDJK8PgCcBRwO3AhcC0yuSqORgUYGovfo2Rlf9EoZvBf4J69/of9Ds2aiKN3kTKnsAqwBdiO4w/yLqvJ7oQwa2aSbeQkX5Vn0DaHq20KzeRQpon7ZyoUQo58qZTCB9nkUONzMJpuZAW8HHswKvBN4Txbvg8A3K/I5F/iCu28DdgUc2JEpiRFlzZrg0GTNmuLwpUvrj2m8sjwXLQq/OH5ZeCt5LF0Kl1wSjmWyN6qbEEIAnS06M7NPAe8DXgLuBf7c3V80swOBGwgfl+8FTnP3FwvSvxq41t3/OLt+L3AR8CxwvLtvLiu7F4vOGi2smj8f7ryzdmzWa1LRorFmFpM1yiP3mpZ7NOt0YZkQYnxTtehMK5CFEGJAqFIGnZiJBoqtW2HJknCE8J/2rbeG6/j49NPhP/W//mtYsaIWPjzcX/mFEKKKSf0WYKyQ2+cBLr64ZoNfvLhmqlm6FE44ISgBgAkT4G/+JoSvXAnHHdc/+YUQogopgyZZvLj+uHBheMHPnw9z59aO8+bBzJmwfXu4PuaYcMw3kRNCiNGIvhk0IP54fNtttV1I2/0Y3GxZzX6gFkKIZtE3gw6Ip5UuWgSnntrZNNFmy9I0UCHESCIzUQNic9Chh9ZGBrHZZ+HC2neCTsxBqelJpiUhxEghZdCA4WG4557wgj7xxFrY6tXwwgtw330wZw4cf3zrjmFShoZqH5n1sVkIMZJIGTQgnUUENbPQjh3gHmYN3XJL+Qs8N/9oRpEQYrQiZdCAdBYR1MxC8cigyqSTm39k9hFCjFb0AbmAfEHZ8DDsvnsYEQwNwU03hR+EWUO77gqHHx5MRFC/uCzOIzf/9HJmUFyeEEK0SlvKwMxeb2bro99vzOys7N40M7vdzB7OjlML0s8zs/vNbK2ZzcrCppjZbWbWdwVVtKlbOmOo6DpOM9Ibw2kjOiFEJ3S8zsDMJgJPAH/g7hvN7DLgaXf/jJmdD0x198VJmpuAvwJmAie4+zlmdjmw2t3vaqbcXq4zKPrgm64lgJ2v4zQjvTGcNqITQjSi1+sM3g781N03ZtfvBq7Lzq8Dji9Is42wRfVkYJuZHQTs16wi6DXxrJ7Y1HPiieE3NFR/DcUv4m3bgsLoxv5EjcxAI2GKEkKMX7qhDE4mOLLP2dvdN2XnTwJ7F6T5NPBV4ALgfwJ/B1zYBVm6SrOml0ZmpW4sIpMZSAjRSzr1ZzAE/AJ4o7v/Mgt71t2nRHGecfedvhtE998KnAB8EbiYMGo4J88viXsGwQ8yM2bMeNPGjRvTKF2lWdNLI7PSggWdby8hM5AQolN6aSZ6F/DD5MX9SzPbJyt4H+CpCsGMMCK4GPhb4DyC/+O/Korv7te4+xx3nzN9+vQORa8mfvlC6yaa1KzUKTIDCSF6SafK4BTqTUQAqwiuLqGxy8sPAN9296cJ3w920CeXlymxWaZTE41MPEKI0U7bZiIz243gB/lAd/91FL4nsAKYAWwEFmUv+zT9ZOBbwAJ332ZmbwH+ARgGTnX3h6rK7/WupenIoBMTjUw8QojRgNxetkHRttR6qQshxjLawroNirallrlHCDFe0d5EJRRtS609hoQQ4xWNDChe0FU0G2hoKGxlfdFFQVFoHyAhxHhByoDWzD9Ll8KnPw2nnCJzkRBi/CAzEa2ZfxYvDs7uZ8+WuUgIMX7QyIDiBV2x6Sjd0vqii8L21UIIMV6QMiihatGZZhUJIcYbMhOVkJqO4nPNKhJCjDekDCrYtg1uvhl22aW28Azqt7gWQojxgJRBCfmiM3cwC0pBCkAIMV6RMighX3S2bVsYGcgkJIQYz7T9ATnzWXyjmf3EzB40syOy8DHrA3l4GJYvh/POg1tuCX4IJk+uNxEJIcR4pJMX7+eBf3X3NwC/DzyYhZ8P3OHus4A7suuUc4BjgLOAD2dhFwKXuvuODmTqiDVr4NRT4bOfDYvKuuGhTAghxgJtmYnMbA/grcCHANx9mLD1NAQfyEdl59cBdwGLkyxGpQ/khQvha1+Ddetgzhw45hiYO1cmIiHE+KetLazNbDZwDfBjwqhgHXCmu/82dnuZeTJ7JnaDGaW/GngBeD9wObDE3R9uUO6Iur0UQojxRC+2sJ4EHAZ80d0PBX5LgTnIg6bZSdu4+3p3P9zd5wMHApuCnLbczK43s72LCh0pt5dbt8KSJeEohBCDQLvK4HHgcXe/O7u+kaAcoIc+kEeKpUvhkkvCUQghBoG2vhm4+5Nm9piZvT5zT/l2gskIaj6QP0MLPpAzN5ijwgfy4sX1RyGEGO90ss7g48AyMxsC/gP4syz8M8AKMzudzAdyUeLs5f8hYEEW9Dng22Q+kDuQqy1yN5f5uoIlSzSdVAgxOLStDNx9PbDThwh330IYKTRK/zwwP7r+LvB77crTKVpxLIQYZLQCOUMrjoUQg4yUQUbu5lIIIQYR+TMQQgghZSCEEELKQAghBFIGQgghkDIQQgjBgCuDdA+i4WG49dZwFEKIQWKglUG6B9GaNfJfIIQYTAZ6nUG6B9HChbBypRacCSEGj4EeGQwNBec1+R5EQ0NhC4p0TyKZj4QQ451OfCD/3Mx+ZGbrzWxtFD5mfCA3axaS+UgIMd7p9MU7391nJ55zxowP5GbNQjIfCSHGO734L/zdBN/HZMfjC+KMCh/IZWahduMJIcRYpZMPyA7cZmYOfMndr8nC93b3Tdn5k0CRC8tPA1+l3gfyhY0KTHwgdyC6EEKImE5GBke6+2HAu4CPmdlb0whj1QeyEEIMGm0rA3d/Ijs+BdwMzM1ujTkfyMPDcNNN4acZQ0KIQaQtZWBmu5nZq/JzguvKDdnt3AcytOADmfD9oC8+kHMvZ4sWacaQEGIwafebwd7AzeEfeyYBX3P3f83ujTkfyLmXs/xcCCEGDQtm/bHHnDlzfO3atY0jCiGEAMDM1iVLAV5moFcgCyGECEgZCCGEkDJI0T5EQohBRMogQfsQCSEGESmDBO1DJIQYRAZeGaRmIe1DJIQYRAZeGcgsJIQQUgYyCwkhBAPu9hJqZiEhhBhkBnJkoOmjQghRz0AqA30nEEKIejpWBmY20czuNbPVUdgBZna3mT2S+SjYaW6OmZ1kZg+Y2XfNbM8s7CAzW96pTI3QdwIhhKinGyODM4EHk7ClwBXu/lrgGeD0gnQfB94MfInaLqWX0ITHs06Jp4/KZCSEEB0qAzPbF/hj4B+jMAPeBtyYBZX5Qd4BvIKaH+S3AE+6+8OdyNQqMhkJIUTns4muJHgne1UUtifwrLu/lF0/DrymIO2ngX8DfgGcBnwDOLmqsF74QJbJSAghOhgZmNmxwFPuvq6d9O5+u7u/yd2PA95NcGzzOjO70cyuzZzfpGm67gM5nloqc5EQYlDpxEw0D/gTM/s5cAPwNjO7HtgCTDGzfNSxL/BEWSaRx7OrgE8RXGV+D/jTDmRrGZmLhBCDTNvKwN0vcPd93X0mwbzz7+5+mgfXaXcC78miNvKDfC7wBXffBuwKOH3wgyxzkRBikOnVOoPFwCfM7BHCN4R/KopkZq8G5rr7LVnQ3wM/AD4MfK1HstWh2URCCCEfyNx6azAPLV4MS5eG0YG2pxBCjEeqfCAP/N5EuXlo/nyYO1dmIiHEYDLwyiCeTaQRgRBiUBnIvYmEEELUI2UghBBCykCziYQQQspAi82EEAIpAy02E0IIBlwZDA+HEcH8+eEoU5EQYlAZaGWQm4iWLpWpSAgx2Az0OgMtOBNCiEAnW1i/0szuMbP7MveVn4rujWq3lzmxxzMhhBhkOjETvQi8zd1/H5gNHG1mh2f3RrXbyxTNKBJCDDqdbGHt7r41u9wl+/lYc3sJmlEkhBAdfTMws4nAOuC1wFXufreZ7UWP3F52g+FhWL06nB97bDARxfsTCSHEINLRbCJ33+7uswnezOaa2SEtpG3Z7aWZnWFma81s7ebNm9uSec0aWLQo/GQWEkKIQFemlrr7swTvZkfTQ7eX3fCBvHAhrFgRfjILCSFEoJPZRNPNbEp2vivwTuAno93t5dBQMA9BMBdpoZkQQnT2zWAf4Lrsu8EEYIW7Z9Z4FgM3mNklwL00dnuZT0vN3V4+S/FH566Qm4oAbr5Z3wuEEGIg3V4WfUQWQojxjtxeJgwNwYkn9lsKIYQYPQz03kRCCCECUgZCCCGkDIQQQkgZCCGEQMpACCEEUgZCCCGQMhBCCIGUgRBCCKQMhBBCIGUghBCCNpWBme1nZnea2Y8zP8ZnRvemmdntZvZwdpxakH6emd2f+SaYlYVNMbPbzEwKSgghRph2X7wvAee4+8HA4cDHzOzg7N75wB3uPgu4I7tOOQc4BjgL+HAWdiFwqbvvaFMmIYQQbdKWMnD3Te7+w+z8OeBBaq4t303wewzl/o+3EfwV5P6PDwL2c/e72pGnHbZuhSVLwlEIIQadjnctNbOZwKHA3VnQ3u6+KTt/Eti7INmnga8CLwDvBy4njAwalXUGcAbAjBkzOpJ76VK45JJwfvHFHWUlhBBjno6UgZntDqwEznL336T33d3NbCeHCe6+nmBewszeCmwKp7acMGo4x91/WZDuGuAaCP4MOpF98eL6oxBCDDKduL3chaAIlrn7TdGtX5rZPlmcfYCnKvIwwojgYuBvgfOAa4G/aleuZhkagrlz5dhGCCGg/dlERnBl+aC7fy65vYrg9xga+z/+APBtd3+a8P1gBz30fxyzZg2cdFI4CiHEoNOumWgewdb/IzNbn4X9jbt/G/gMsMLMTgc2AouKMjCzycCHgAVZ0OeAbwPDwKltytU0CxfCypXhKIQQg05bysDdvwdYyb0twNubyON5YH50/V3g99qRp1WGh8OIYOFCmYmEEAIGdAWyTERCCFHPQCoDmYiEEKKejtcZjEWGhuC44/othRBCjB4GcmQghBCiHikDIYQQUgZCCCGkDIQQQiBlIIQQAikDIYQQSBkIIYRAykAIIQSdbWH9ZTN7ysw2JOHygSyEEGOMTl68XwGOLgiXD2QhhBhjtK0M3P07wNMFt8aED2QhhBA1erE30ZjwgSyEEKJGT+3z7u5AoQ9kdz/c3ecDBxL5QDaz682sSIHg7te4+xx3nzN9+vReii6EEANFL5TBmPCBLIQQokYvlMGo9oE8PAy33hqOQgghAp1MLf068H+A15vZ45nPYwg+kN9pZg8D78iui9LnPpCvyoJyH8hXAle3K1cj5OVMCCF2xoJZf+wxZ84cX7t2bcvp5P9YCDGomNk6d59TdG/gPJ3Jy5kQQuyMVvsKIYSQMhBCCCFlIIQQAikDIYQQSBkIIYRAykAIIQRSBkIIIZAyEEIIgZSBEEIIpAyEEELQI2VgZkeb2UNm9oiZFbm9xMyWZn6QvxqFnWZmZ/VCJiGEEOV0XRmY2UTCTqTvAg4GTjGzg5M4ewCHuft/AYbN7PfMbFfgz6jtYiqEEGKE6MXIYC7wiLv/h7sPAzcQ/CLH7AB2yZzbTCb4RP5r4O/dfVsPZHoZ+TMQQoid6YUyeA3wWHT9eBb2Mu7+HMF3wb0El5e/Bv7A3W+pytjMzjCztWa2dvPmzW0JJ38GQgixM337gOzul7n7bHc/h+D28r+b2Z+b2Qozu7AkTcc+kBcuhJUrw1EIIUSgF8rgCWC/6HrfLKwQMzsUMOAh4L3uvgg4yMxm9UC2l/0ZyLGNEELU6IUy+AEwy8wOMLMh4GSCX+QyLgaWALsAE7OwnvpBFkIIUU/XPZ25+0tm9t+ANYSX+5fd/YGiuGZ2PLDW3X+RXa83sx8B97v7fd2WTQghRDED5wNZCCEGlSofyFqBLIQQQspACCGElIEQQgikDIQQQjCGPyCb2WZgY5vJ9wJ+1UVx+sV4qQeoLqOR8VIPUF1y9nf3whW7Y1YZdIKZrS37oj6WGC/1ANVlNDJe6gGqSzPITCSEEELKQAghxOAqg2v6LUCXGC/1ANVlNDJe6gGqS0MG8puBEEKIegZ1ZCCEECJCykAIIcRgKQMzO9rMHjKzR8zs/H7L0wgz28/M7jSzH5vZA2Z2ZhY+zcxuN7OHs+PULNzM7AtZ/e43s8P6W4N6zGyimd1rZquz6wPM7O5M3uXZlueY2Suy60ey+zP7KniCmU0xsxvN7Cdm9qCZHTGG++Ts7NnaYGZfN7NXjpV+MbMvm9lTZrYhCmu5H8zsg1n8h83sg6OkHp/Nnq/7zexmM5sS3bsgq8dDZrYwCu/s/ebuA/EjbKf9U+BAYAi4Dzi433I1kHkf4LDs/FXA/wMOBi4Dzs/CzweWZufHAP9CcBZ0OHB3v+uQ1OcTwNeA1dn1CuDk7Pxq4CPZ+UeBq7Pzk4Hl/ZY9qcd1wJ9n50PAlLHYJwR3tD8Ddo3640NjpV+AtwKHARuisJb6AZgG/Ed2nJqdTx0F9VgATMrOl0b1ODh7d70COCB7p03sxvut7w/kCDb4EcCa6PoC4IJ+y9ViHb4JvJPgFW6fLGwf4KHs/EvAKVH8l+P1+0fweHcH8DZgdfZH+avogX+5fwi+MI7Izidl8azfdcjk2SN7gVoSPhb7JPdXPi1r59XAwrHUL8DM5CXaUj8ApwBfisLr4vWrHsm9E4Bl2Xndeyvvk2683wbJTJQ/+DmPZ2FjgmxIfihwN7C3u2/Kbj0J7J2dj+Y6XgmcR/BiB7An8Ky7v5Rdx7K+XI/s/q+z+KOBA4DNwP/KTF7/aGa7MQb7xN2fAC4HHgU2Edp5HWOzX3Ja7YdR2z8R/5UwqoEe1mOQlMGYxcx2B1YCZ7n7b+J7Hv4NGNXzg83sWOApd1/Xb1m6wCTCkP6L7n4o8FuCOeJlxkKfAGT29HcTFNyrgd2Ao/sqVBcZK/1QhZl9EngJWNbrsgZJGTwB7Bdd75uFjWrMbBeCIljm7jdlwb80s32y+/sAT2Xho7WO84A/MbOfAzcQTEWfB6aYWe56NZb15Xpk9/cAtoykwBU8Djzu7ndn1zcSlMNY6xOAdwA/c/fN7r4NuInQV2OxX3Ja7YdR2z9m9iHgWOBPM8UGPazHICmDHwCzspkSQ4QPYKv6LFMlZmbAPwEPuvvnolurgHzWwwcJ3xLy8A9kMycOB34dDZn7hrtf4O77uvtMQrv/u7v/KXAn8J4sWlqPvH7vyeKPiv/w3P1J4DEze30W9Hbgx4yxPsl4FDjczCZnz1pelzHXLxGt9sMaYIGZTc1GSguysL5iZkcTzKp/4u7PR7dWASdnM7sOAGYB99CN91s/P/704SPNMYQZOT8FPtlveZqQ90jCMPd+YH32O4Zgp70DeBj4N2BaFt+Aq7L6/QiY0+86FNTpKGqziQ7MHuRHgG8Ar8jCX5ldP5LdP7Dfcid1mA2szfrlFsIslDHZJ8CngJ8AG4B/JsxSGRP9Anyd8K1jG2HEdno7/UCwyT+S/f5slNTjEcI3gPzv/uoo/iezejwEvCsK7+j9pu0ohBBCDJSZSAghRAlSBkIIIaQMhBBCSBkIIYRAykAIIQRSBkIIIZAyEEIIAfx/olJQWAfjfLQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(list(range(epochs+1)), accuracies1, s=0.5, color=\"blue\")#s=1\n",
    "yticks = [str(i)+\" %\" for i in range(0,101,10)]\n",
    "plt.yticks(list(range(0,101,10)), yticks)\n",
    "plt.scatter([0],[100], s=0.000001)\n",
    "plt.plot([0,1202],[90,90], color=\"green\")\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9903d922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracies1_late = np.array(accuracies1[600:])\n",
    "plt.hist(accuracies1_late, bins=np.arange(accuracies1_late.min(), accuracies1_late.max()+1))\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "18a02d15",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'describe'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43maccuracies1_late\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdescribe\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'describe'"
     ]
    }
   ],
   "source": [
    "accuracies1_late.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646cf79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(list(range(epochs)), costs1, color=\"red\", s=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edee5e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del nn, layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adee07a9",
   "metadata": {},
   "source": [
    "#### 5.1.2 Entrainement sur mini_batch , test sur tout le data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bb6f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCE2 = SoftmaxCrossEntropyLoss()\n",
    "layers2 = [DenseActivatedLayer(112, 784, ReLu), OutputLayer(16, 112, SCE2)]\n",
    "nn2 = NeuralNetwork(layers2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20919d29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "accuracies2, costs2 = train_on_subset(nn2, \"./EMNIST_DATA_SET/\", epochs=epochs, \n",
    "                                      batch_size=64, equilibrium=True, lr=1, \n",
    "                                      test_on_all=True, iter_test=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e79e68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(range(0,epochs,20)))\n",
    "plt.plot(list(range(0, epochs+20, 20)), accuracies2)#s=1\n",
    "yticks = [str(i)+\" %\" for i in range(0,101,10)]\n",
    "plt.yticks(list(range(0,101,10)), yticks)\n",
    "plt.scatter([0],[100], s=0.000001)\n",
    "plt.plot([0,epochs+1],[90,90], color=\"red\")\n",
    "plt.rcParams[\"figure.figsize\"] = (20,15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6b78f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(range(0,epochs, 20)), costs2, color=\"red\")#, s=4\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd4ac17",
   "metadata": {},
   "source": [
    "### 5.2 Exemple concret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520a140d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = make_random_batch(\"./EMNIST_DATA_SET/\", 64, CLASSES, equilibrium=False)\n",
    "imgs = [load_pil_image(f) for f in batch]\n",
    "l = image_grid(imgs, titles=[\" \"]*len(batch))\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3379c7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in range(len(batch)): \n",
    "    x, im = load_prediction_image(batch[i])\n",
    "    p = nn.forward(x)\n",
    "    res.append(predicted_labels(p)[0])\n",
    "image_grid(imgs, titles=res)\n",
    "#print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d17b905",
   "metadata": {},
   "source": [
    "sauvegarde du models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f31ad32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bad8504",
   "metadata": {},
   "source": [
    "## 6. Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ed26f6",
   "metadata": {},
   "source": [
    "68 74 74 70 73 3A 2F 2F 79 6F 75 74 75 2E 62 65 2F 64 51 77 34 77 39 57 67 58 63 51 3F 74 3D 34 32\n",
    "\n",
    "https://youtu.be/dQw4w9WgXcQ?t=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dcaf8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d45d17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050e1662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b92bd2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c941394c",
   "metadata": {},
   "source": [
    "## 7.Ouverture et extensions possibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3837165f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d465a539",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bddf2efe",
   "metadata": {},
   "source": [
    "Utile mais pas encore note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def2cf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inspect.getsource(load_pil_image))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
